{"cells":[{"cell_type":"code","execution_count":26,"metadata":{"id":"rVL_4fRnvcw0"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","RAMDOM_STATE = 11"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1683121718900,"user":{"displayName":"Vitor Berger Bonella","userId":"08385931327396340646"},"user_tz":180},"id":"UwI7Hq6NwmWC","outputId":"5193b38e-63f6-43e5-926c-67baa055c69b"},"outputs":[],"source":["df = pd.read_csv('https://raw.githubusercontent.com/VitorBonella/PL-Dataset/main/dataset.csv',sep=\";\") #Leitura dos dados para o pandas"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1683121718901,"user":{"displayName":"Vitor Berger Bonella","userId":"08385931327396340646"},"user_tz":180},"id":"rU0oAiZHx27G","outputId":"08636a2e-d1a1-4cba-9292-08554aba8ca9"},"outputs":[],"source":["df.set_index('id',inplace=True) #Transformando a coluna id no indice da tabela\n","\n","#Observem que a classe esta separada em duas colunas então devemos concatenadas para formar uma coluna só chamada classe\n","df['classe'] = df['tipo_lampada'].str.replace(\" \", \"\") + df['potencia'].astype(str) "]},{"cell_type":"code","execution_count":29,"metadata":{"id":"OO1VX46PxklS"},"outputs":[],"source":["# Lista de Indices\n","HU = ['i1', 'i2', 'i3', 'i4','i5', 'i6', 'i7']\n","MY = HU\n","\n","df[MY] = df[MY].apply(lambda x: x.str.replace(',', '.').astype(float), axis=1)\n","\n","X = df[MY]\n","Y = df['classe']"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1683121718905,"user":{"displayName":"Vitor Berger Bonella","userId":"08385931327396340646"},"user_tz":180},"id":"LjOhhRUoz6MA","outputId":"378b52e6-d8b5-470c-e619-4819d8fa1b8d"},"outputs":[],"source":["results_df = pd.DataFrame(columns=['Método', 'Média', 'Desvio padrão', 'Limite inf.', 'Limite sup.'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### zeroR"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.1563405797101449\n","<class 'numpy.ndarray'>\n"]}],"source":["from sklearn.model_selection import cross_val_predict \n","from sklearn.dummy import DummyClassifier\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","\n","zR = DummyClassifier(strategy='most_frequent')\n","\n","cv_zR = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=RAMDOM_STATE)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=RAMDOM_STATE)\n","\n","scores_ZR = cross_val_score(zR, X_train, y_train, scoring='accuracy', cv=cv_zR)\n","\n","inf, sup = stats.norm.interval(0.95, loc=scores_ZR.mean(), scale=scores_ZR.std()/np.sqrt(len(scores_ZR)))\n","\n","results_df = pd.concat([results_df, pd.DataFrame({'Método': ['ZR'], 'Média': [scores_ZR.mean()], 'Desvio padrão': scores_ZR.std(), 'Limite inf.': inf, 'Limite sup.': sup})], ignore_index=True)\n","\n","print(scores_ZR.mean())\n","print(type(scores_ZR))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","\n","def train_models(model, params_grid, name):\n","    scalar = StandardScaler()\n","    pipe = Pipeline(steps=[('s',scalar), ('m', model)])\n","\n","    inner_cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=RAMDOM_STATE)\n","\n","    outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=RAMDOM_STATE)\n","\n","    grid_search = GridSearchCV(pipe, param_grid=params_grid,  scoring='accuracy', cv=inner_cv, n_jobs=-1)\n","\n","    scores = cross_val_score(grid_search, X, Y.values.ravel(), scoring='accuracy', cv=outer_cv, n_jobs=-1)\n","\n","    inf, sup = stats.norm.interval(0.95, loc=scores.mean(), scale=scores.std()/np.sqrt(len(scores)))\n","\n","    local_df = pd.concat([results_df, pd.DataFrame({'Método': [name], 'Média': [scores.mean()], 'Desvio padrão': scores.std(), 'Limite inf.': inf, 'Limite sup.': sup})], ignore_index=True)\n","\n","    return local_df, scores"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import BaggingClassifier\n","\n","\n","bg = BaggingClassifier(n_estimators=3, random_state=RAMDOM_STATE)\n","\n","params_grid = {\n","    'm__n_estimators': [3,9,15,21]\n","    } \n","\n","results_df, scores_BA = train_models(bg, params_grid, 'BA')"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","ada = AdaBoostClassifier(n_estimators=3, random_state=RAMDOM_STATE)\n","\n","params_grid = {\n","    'm__n_estimators': [3,9,15,21]\n","    }\n","\n","results_df, scores_AD = train_models(ada, params_grid, 'AD')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","\n","rf = RandomForestClassifier(random_state=RAMDOM_STATE)\n","\n","params_grid = {\n","    'm__n_estimators': [3,9,15,21]\n","}\n","\n","results_df, scores_RF = train_models(rf, params_grid, 'RF')"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Método</th>\n","      <th>Média</th>\n","      <th>Desvio padrão</th>\n","      <th>Limite inf.</th>\n","      <th>Limite sup.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ZR</td>\n","      <td>0.156341</td>\n","      <td>0.020735</td>\n","      <td>0.148921</td>\n","      <td>0.163761</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BA</td>\n","      <td>0.461571</td>\n","      <td>0.096206</td>\n","      <td>0.427145</td>\n","      <td>0.495997</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AD</td>\n","      <td>0.257165</td>\n","      <td>0.027720</td>\n","      <td>0.247246</td>\n","      <td>0.267084</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RF</td>\n","      <td>0.472797</td>\n","      <td>0.074776</td>\n","      <td>0.446039</td>\n","      <td>0.499555</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Método     Média  Desvio padrão  Limite inf.  Limite sup.\n","0     ZR  0.156341       0.020735     0.148921     0.163761\n","1     BA  0.461571       0.096206     0.427145     0.495997\n","2     AD  0.257165       0.027720     0.247246     0.267084\n","3     RF  0.472797       0.074776     0.446039     0.499555"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["results_df"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["from sklearn.base import BaseEstimator\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.utils.validation import check_X_y\n","from sklearn.utils import resample\n","from collections import Counter\n","\n","\n","class HeterogeneousPooling(BaseEstimator):\n","    # define o construtor para o classificador\n","    def __init__(self, n_samples=3):\n","        self.classifiers = [DecisionTreeClassifier(random_state=RAMDOM_STATE), KNeighborsClassifier(), GaussianNB()]\n","        self.n_samples = n_samples\n","        self.trained_classifiers = []\n","\n","    def fit(self, X, y):\n","\n","         # se os dados forem uma matriz numpy, converta para dataframe pandas\n","        if isinstance(X, np.ndarray):\n","            X = pd.DataFrame(X)\n","        if isinstance(y, np.ndarray):\n","            y = pd.Series(y)\n","\n","        # reset index\n","        X.reset_index(drop=True, inplace=True)\n","        y.reset_index(drop=True, inplace=True)\n","        \n","        self.counter = Counter(y)\n","\n","        for i in range(self.n_samples):\n","            if i == 0:\n","                X_train = X\n","                y_train = y\n","            else:\n","                X_train, y_train = resample(X, y, replace=True, random_state=RAMDOM_STATE)\n","\n","            self.train_classifiers(X_train, y_train)\n","        return self\n","    \n","    def train_classifiers(self, X, y):\n","        \n","        for classifier in self.classifiers:\n","            classifier.fit(X, y.ravel())\n","            self.trained_classifiers.append(classifier)\n","\n","    def predict(self, X):\n","        predictions = []\n","\n","        for _, row in X.iterrows():\n","            # print(row)\n","            predictions.append(self.unique_predict(row.values.reshape(1, -1)))\n","\n","        print(\"predicts\",predictions)\n","\n","        return np.mdArray(predictions)\n","\n","    def unique_predict(self, X):\n","        predictions = {}\n","\n","        for classifier in self.trained_classifiers:\n","            pred = classifier.predict(X)\n","            print(pred)\n","\n","            # try:\n","            predictions[pred[0]] += 1\n","            # except:\n","                # predictions[pred[0]] = 1\n","        \n","        # verificar se existe mais de uma classe com a mesma quantidade de votos\n","        max_votes = max(predictions.values())\n","        max_classes = [k for k, v in predictions.items() if v == max_votes]\n","\n","        if len(max_classes) > 1:\n","            # se sim, retornar a classe mais frequente na base de treino\n","            return self.counter.most_common(1)[0][0]\n","        else:\n","            # se não, retornar a classe mais votada\n","            return max_classes[0]\n","\n","        "]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan]\n"]}],"source":["hp = HeterogeneousPooling()\n","# hp.fit(X_train, y_train)\n","\n","# print(hp.predict(X_test))\n","\n","\n","params_grid = {\n","    'm__n_samples': [1,3,5,7]\n","}\n","\n","def train_models1(model, params_grid, name):\n","    scalar = StandardScaler()\n","    pipe = Pipeline(steps=[('s',scalar), ('m', model)])\n","\n","    inner_cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=RAMDOM_STATE)\n","\n","    outer_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=RAMDOM_STATE)\n","\n","    grid_search = GridSearchCV(pipe, param_grid=params_grid,  scoring='accuracy', cv=inner_cv, n_jobs=-1)\n","\n","    scores = cross_val_score(grid_search, X, Y.values.ravel(), scoring='accuracy', cv=outer_cv, n_jobs=-1)\n","    print(scores)\n","\n","    inf, sup = stats.norm.interval(0.95, loc=scores.mean(), scale=scores.std()/np.sqrt(len(scores)))\n","\n","    local_df = pd.concat([results_df, pd.DataFrame({'Método': [name], 'Média': [scores.mean()], 'Desvio padrão': scores.std(), 'Limite inf.': inf, 'Limite sup.': sup})], ignore_index=True)\n","\n","    return local_df, scores\n","\n","results_df, scores_HP = train_models1(hp, params_grid, 'HP')"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Método</th>\n","      <th>Média</th>\n","      <th>Desvio padrão</th>\n","      <th>Limite inf.</th>\n","      <th>Limite sup.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ZR</td>\n","      <td>0.156341</td>\n","      <td>0.020735</td>\n","      <td>0.148921</td>\n","      <td>0.163761</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BA</td>\n","      <td>0.461571</td>\n","      <td>0.096206</td>\n","      <td>0.427145</td>\n","      <td>0.495997</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AD</td>\n","      <td>0.257165</td>\n","      <td>0.027720</td>\n","      <td>0.247246</td>\n","      <td>0.267084</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RF</td>\n","      <td>0.472797</td>\n","      <td>0.074776</td>\n","      <td>0.446039</td>\n","      <td>0.499555</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HP</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Método     Média  Desvio padrão  Limite inf.  Limite sup.\n","0     ZR  0.156341       0.020735     0.148921     0.163761\n","1     BA  0.461571       0.096206     0.427145     0.495997\n","2     AD  0.257165       0.027720     0.247246     0.267084\n","3     RF  0.472797       0.074776     0.446039     0.499555\n","4     HP       NaN            NaN          NaN          NaN"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["results_df"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'0'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[77], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m wilcoxon \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mwilcoxon(scores[i], scores[j], method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mapprox\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# save results\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m comparative_results[\u001b[39mstr\u001b[39;49m(i)][\u001b[39mstr\u001b[39m(j)] \u001b[39m=\u001b[39m [ttest[\u001b[39m1\u001b[39m], wilcoxon[\u001b[39m1\u001b[39m]]\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(models_names[i] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m x \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m models_names[j])\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mttest: \u001b[39m\u001b[39m'\u001b[39m, comparative_results[\u001b[39mstr\u001b[39m(i)][\u001b[39mstr\u001b[39m(j)][\u001b[39m0\u001b[39m])\n","\u001b[1;31mKeyError\u001b[0m: '0'"]}],"source":["from scipy import stats \n","# ttest and wilcoxon test\n","\n","scores = [scores_ZR, scores_BA, scores_AD, scores_RF, scores_HP]\n","models_names = ['ZeroR', 'BG', 'AB', 'RF', 'HP']\n","\n","qtd_models = 4\n","\n","comparative_results = {}\n","\n","for i in range(qtd_models):\n","    for j in range(i+1, qtd_models):\n","        comparative_results[i] = {}\n","        # ttest\n","        ttest = stats.ttest_rel(scores[i], scores[j])\n","        # wilcoxon\n","        wilcoxon = stats.wilcoxon(scores[i], scores[j], method='approx')\n","        # save results\n","        comparative_results[str(i)][str(j)] = {'ttest' = ttest[1], 'wilcoxon' = wilcoxon[1]}\n","        print(models_names[i] + ' x ' + models_names[j])\n","        print('ttest: ', comparative_results[i][j][0])\n","        print('wilcoxon: ', comparative_results[i][j][1])\n","\n","for i in range(qtd_models):\n","    for j in range(i+1, qtd_models):\n","        print(models_names[i] + ' x ' + models_names[j])\n","        print('ttest: ', comparative_results[i][j][0])\n","        \n","\n","\n","# tabela com os resultados dos testes, t student no superior e wilcoxon no inferior\n","# table = pd.DataFrame(columns=models_names, index=models_names)\n","\n","# for i in range(len(models_names)):\n","#     for j in range(i, len(models_names)):\n","#         # se o index for igual a coluna \n","#         if i == j:\n","#             table.loc[models_names[i], models_names[j]] = models_names[i]\n","\n","#         else:\n","#             table.loc[models_names[i], models_names[j]] = comparative_results[models_names[i] + ' x ' + models_names[j]][0][1]\n","#             table.loc[models_names[j], models_names[i]] = comparative_results[models_names[i] + ' x ' + models_names[j]][1][1]\n","\n","# print(table)\n","\n","\n","# table.to_csv('tstudent_wilcoxon.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
